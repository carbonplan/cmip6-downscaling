{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31621b4-3bb2-49cc-ba66-761c347167db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5cf5ef-7a5c-44f3-b9a5-a8ea33859217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "os.environ['PREFECT__FLOWS__CHECKPOINTING'] = 'true'\n",
    "\n",
    "from funnel import CacheStore\n",
    "from funnel.prefect.result import FunnelResult\n",
    "from prefect import task, Flow, Parameter\n",
    "from prefect.executors import DaskExecutor\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76964487-7065-4f72-a590-e8d5397a1fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DefaultEndpointsProtocol=https;AccountName=cmip6downscaling;AccountKey=q2TSTCMWAAf0IRwwZc3Yhhi8vrvYkRynAvS5FPl0amcqZ/gXpbB1BCfYmUYBwasJPYb9VrPjlBHgEwY3M84nSA==;EndpointSuffix=core.windows.net'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get(\"AZURE_STORAGE_CONNECTION_STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21621ece-a7fb-4bc8-9996-9466c5180831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import os \n",
    "connection_string = os.environ.get(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "\n",
    "fs = fsspec.filesystem('az', connection_string=connection_string)\n",
    "\n",
    "# # fs.rm('flow-outputs/intermediate/bias_corrected_gcm',recursive=True)\n",
    "# # fs.rm('flow-outputs/intermediate/funnel_metadata_store/bias_corrected_gcm',recursive=True)\n",
    "# # fs.rm('flow-outputs/intermediate/bias_corrected_obs',recursive=True)\n",
    "# # fs.rm('flow-outputs/intermediate/funnel_metadata_store/bias_corrected_obs',recursive=True)\n",
    "# fs.rm('flow-outputs/intermediate/interpolated_obs',recursive=True)\n",
    "# fs.rm('flow-outputs/intermediate/epoch_adjusted_gcm', recursive=True)\n",
    "# fs.rm('flow-outputs/intermediate/gcm_epoch_trend', recursive=True)\n",
    "# fs.rm('flow-outputs/intermediate/maca_epoch_adjusted_downscaled_output', recursive=True)\n",
    "# fs.rm('flow-outputs/intermediate/epoch_replaced_gcm', recursive=True)\n",
    "\n",
    "# fs.rm('flow-outputs/intermediate/maca_test_bias_correction_rechunk.zarr', recursive=True)\n",
    "# fs.rm('flow-outputs/intermediate/maca_epoch_adjusted_downscaled_output/MIROC6_ssp370_1991_1995_2071_2075_tasmax_tasmax_0.0_-90.0_360.0_90.0.zarr', recursive=True)\n",
    "# fs.rm('flow-outputs/intermediate/rechunked_obs/ERA5_1991_1995_tasmax_full_time.zarr', recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c29b7c8-34cd-4c9d-ae46-f5b2c2409cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hyperparameters = {\n",
    "    \"OBS\": \"ERA5\",\n",
    "    \"GCM\": \"MIROC6\",\n",
    "    \"SCENARIO\": \"ssp370\",\n",
    "    \"LABEL\": \"tasmax\",\n",
    "    \"TRAIN_PERIOD_START\": \"1991\",\n",
    "    \"TRAIN_PERIOD_END\": \"1995\",\n",
    "    \"PREDICT_PERIOD_START\": \"2071\",\n",
    "    \"PREDICT_PERIOD_END\": \"2075\",\n",
    "    \"EPOCH_ADJUSTMENT_DAY_ROLLING_WINDOW\": 21, \n",
    "    \"EPOCH_ADJUSTMENT_YEAR_ROLLING_WINDOW\": 3,\n",
    "    \"BIAS_CORRECTION_BATCH_SIZE\": 15,\n",
    "    \"BIAS_CORRECTION_BUFFER_SIZE\": 15,\n",
    "    \"CONSTRUCTED_ANALOG_N_ANALOGS\": 10,\n",
    "    \"CONSTRUCTED_ANALOG_DOY_RANGE\": 45,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2c90bad-8866-4754-ac90-4f4a212c2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmip6_downscaling.workflows.maca_flow import maca_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c355712-2f6e-4cfb-8da5-a040a124e111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-08 06:58:33+0000] INFO - prefect.FlowRunner | Beginning Flow run for 'maca-flow'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'SCENARIO': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'SCENARIO': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'BIAS_CORRECTION_BATCH_SIZE': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'BIAS_CORRECTION_BATCH_SIZE': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'BIAS_CORRECTION_BUFFER_SIZE': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'BIAS_CORRECTION_BUFFER_SIZE': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'PREDICT_PERIOD_START': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'PREDICT_PERIOD_START': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'GCM': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'GCM': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'EPOCH_ADJUSTMENT_YEAR_ROLLING_WINDOW': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'EPOCH_ADJUSTMENT_YEAR_ROLLING_WINDOW': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'CONSTRUCTED_ANALOG_N_ANALOGS': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'CONSTRUCTED_ANALOG_N_ANALOGS': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'CONSTRUCTED_ANALOG_DOY_RANGE': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'CONSTRUCTED_ANALOG_DOY_RANGE': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'TRAIN_PERIOD_START': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'TRAIN_PERIOD_START': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'EPOCH_ADJUSTMENT_DAY_ROLLING_WINDOW': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'EPOCH_ADJUSTMENT_DAY_ROLLING_WINDOW': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'TRAIN_PERIOD_END': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'TRAIN_PERIOD_END': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'LABEL': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'LABEL': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'PREDICT_PERIOD_END': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'PREDICT_PERIOD_END': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'OBS': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'OBS': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:33+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:34+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:34+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:34+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:34+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:34+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:34+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:34+0000] INFO - prefect.TaskRunner | Task 'get_obs': Starting task run...\n",
      "target path is az://flow-outputs/intermediate/rechunked_obs/ERA5_1991_1995_tasmax_full_space.zarr\n",
      "checking the cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/cmip6-downscaling/cmip6_downscaling/workflows/utils.py:526: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  output = xr.open_zarr(target_store)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-08 06:58:36+0000] INFO - prefect.TaskRunner | Task 'get_obs': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:36+0000] INFO - prefect.TaskRunner | Task 'path_builder_task': Starting task run...\n",
      "[2022-01-08 06:58:37+0000] INFO - prefect.TaskRunner | Task 'path_builder_task': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:37+0000] INFO - prefect.TaskRunner | Task 'get_gcm': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/home/jovyan/cmip6-downscaling/cmip6_downscaling/workflows/utils.py:526: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  output = xr.open_zarr(target_store)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target path is az://flow-outputs/intermediate/rechunked_gcm/MIROC6_ssp370_1991_1995_2071_2075_tasmax_full_time.zarr\n",
      "checking the cache\n",
      "[2022-01-08 06:58:38+0000] INFO - prefect.TaskRunner | Task 'get_gcm': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:38+0000] INFO - prefect.TaskRunner | Task 'get_obs': Starting task run...\n",
      "target path is az://flow-outputs/intermediate/rechunked_obs/ERA5_1991_1995_tasmax_full_time.zarr\n",
      "checking the cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/cmip6-downscaling/cmip6_downscaling/workflows/utils.py:526: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  output = xr.open_zarr(target_store)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-08 06:58:41+0000] INFO - prefect.TaskRunner | Task 'get_obs': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:41+0000] INFO - prefect.TaskRunner | Task 'path_builder_task[2]': Starting task run...\n",
      "[2022-01-08 06:58:41+0000] INFO - prefect.TaskRunner | Task 'path_builder_task[2]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:41+0000] INFO - prefect.TaskRunner | Task 'List': Starting task run...\n",
      "[2022-01-08 06:58:41+0000] INFO - prefect.TaskRunner | Task 'List': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:41+0000] INFO - prefect.TaskRunner | Task 'calc_epoch_trend_task': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'calc_epoch_trend_task': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'path_builder_task[1]': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'path_builder_task[1]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/regionmask/core/regions.py:410: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for p in poly:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task[0]': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task[0]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task[3]': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task[3]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'Mul': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'Mul': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'path_builder_task[0]': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'path_builder_task[0]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task[1]': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task[1]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task[2]': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'get_subdomains_task[2]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'Mul': Starting task run...\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'Mul': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:42+0000] INFO - prefect.TaskRunner | Task 'remove_epoch_trend': Starting task run...\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'remove_epoch_trend': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'Mul': Starting task run...\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'Mul': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'get_coarse_obs_task': Starting task run...\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'get_coarse_obs_task': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'Mul': Starting task run...\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'Mul': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'get_coarse_obs_task': Starting task run...\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'get_coarse_obs_task': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:44+0000] INFO - prefect.TaskRunner | Task 'maca_coarse_bias_correction_task': Starting task run...\n",
      "[2022-01-08 06:58:45+0000] INFO - prefect.TaskRunner | Task 'maca_coarse_bias_correction_task': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:45+0000] INFO - prefect.TaskRunner | Task 'rechunker_task': Starting task run...\n",
      "target path is az://flow-outputs/intermediate/bias_corrected_gcm/MIROC6_ssp370_1991_1995_2071_2075_tasmax_full_space_maca_edcdfm.zarr\n",
      "checking the cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/cmip6-downscaling/cmip6_downscaling/workflows/utils.py:526: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  output = xr.open_zarr(target_store)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'rechunker_task': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'subset_task': Starting task run...\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'subset_task': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'subset_task[1]': Starting task run...\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'subset_task[1]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'subset_task[0]': Starting task run...\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'subset_task[0]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'subset_task[2]': Starting task run...\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'subset_task[2]': Finished task run for task with final state: 'Success'\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs': Starting task run...\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs': Finished task run for task with final state: 'Mapped'\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[0]': Starting task run...\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[0]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[1]': Starting task run...\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[1]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:46+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[2]': Starting task run...\n",
      "[2022-01-08 06:58:47+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[2]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:47+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[3]': Starting task run...\n",
      "[2022-01-08 06:58:47+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[3]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:47+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[4]': Starting task run...\n",
      "[2022-01-08 06:58:47+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[4]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:47+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[5]': Starting task run...\n",
      "[2022-01-08 06:58:48+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[5]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:48+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[6]': Starting task run...\n",
      "[2022-01-08 06:58:48+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[6]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:48+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[7]': Starting task run...\n",
      "[2022-01-08 06:58:48+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[7]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:48+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[8]': Starting task run...\n",
      "[2022-01-08 06:58:49+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[8]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:49+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[9]': Starting task run...\n",
      "[2022-01-08 06:58:49+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[9]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:49+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[10]': Starting task run...\n",
      "[2022-01-08 06:58:49+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[10]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:49+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[11]': Starting task run...\n",
      "[2022-01-08 06:58:49+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[11]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:49+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[12]': Starting task run...\n",
      "[2022-01-08 06:58:50+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[12]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:50+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[13]': Starting task run...\n",
      "[2022-01-08 06:58:50+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[13]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:50+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[14]': Starting task run...\n",
      "[2022-01-08 06:58:50+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[14]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:50+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[15]': Starting task run...\n",
      "[2022-01-08 06:58:51+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[15]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:51+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[16]': Starting task run...\n",
      "[2022-01-08 06:58:51+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[16]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:51+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[17]': Starting task run...\n",
      "[2022-01-08 06:58:51+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[17]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:51+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[18]': Starting task run...\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[18]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[19]': Starting task run...\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[19]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[20]': Starting task run...\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[20]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[21]': Starting task run...\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[21]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[22]': Starting task run...\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[22]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:52+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[23]': Starting task run...\n",
      "[2022-01-08 06:58:53+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[23]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:53+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[24]': Starting task run...\n",
      "[2022-01-08 06:58:53+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[24]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:53+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[25]': Starting task run...\n",
      "[2022-01-08 06:58:53+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[25]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:53+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[26]': Starting task run...\n",
      "[2022-01-08 06:58:53+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[26]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:53+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[27]': Starting task run...\n",
      "[2022-01-08 06:58:54+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[27]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:54+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[28]': Starting task run...\n",
      "[2022-01-08 06:58:54+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[28]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:54+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[29]': Starting task run...\n",
      "[2022-01-08 06:58:54+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[29]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:54+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[30]': Starting task run...\n",
      "[2022-01-08 06:58:54+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[30]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:54+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[31]': Starting task run...\n",
      "[2022-01-08 06:58:55+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[31]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:55+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[32]': Starting task run...\n",
      "[2022-01-08 06:58:55+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[32]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:55+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[33]': Starting task run...\n",
      "[2022-01-08 06:58:55+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[33]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:55+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[34]': Starting task run...\n",
      "[2022-01-08 06:58:55+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[34]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:55+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[35]': Starting task run...\n",
      "[2022-01-08 06:58:56+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[35]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:56+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[36]': Starting task run...\n",
      "[2022-01-08 06:58:56+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[36]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:56+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[37]': Starting task run...\n",
      "[2022-01-08 06:58:56+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[37]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:56+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[38]': Starting task run...\n",
      "[2022-01-08 06:58:56+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[38]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:56+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[39]': Starting task run...\n",
      "[2022-01-08 06:58:57+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[39]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:57+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[40]': Starting task run...\n",
      "[2022-01-08 06:58:57+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[40]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:57+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[41]': Starting task run...\n",
      "[2022-01-08 06:58:57+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[41]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:57+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[42]': Starting task run...\n",
      "[2022-01-08 06:58:57+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[42]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:58+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[43]': Starting task run...\n",
      "[2022-01-08 06:58:58+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[43]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:58+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[44]': Starting task run...\n",
      "[2022-01-08 06:58:58+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[44]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:58+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[45]': Starting task run...\n",
      "[2022-01-08 06:58:58+0000] INFO - prefect.TaskRunner | Task 'maca_construct_analogs[45]': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:58+0000] INFO - prefect.TaskRunner | Task 'combine_outputs_task': Starting task run...\n",
      "[2022-01-08 06:58:59+0000] INFO - prefect.TaskRunner | Task 'combine_outputs_task': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:59+0000] INFO - prefect.TaskRunner | Task 'maca_epoch_replacement_task': Starting task run...\n",
      "[2022-01-08 06:58:59+0000] INFO - prefect.TaskRunner | Task 'maca_epoch_replacement_task': Finished task run for task with final state: 'Cached'\n",
      "[2022-01-08 06:58:59+0000] INFO - prefect.TaskRunner | Task 'maca_fine_bias_correction_task': Starting task run...\n",
      "target path is az://flow-outputs/intermediate/maca_test_fine_bias_correction_rechunk.zarr\n",
      "checking the cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/cmip6-downscaling/cmip6_downscaling/workflows/utils.py:526: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  output = xr.open_zarr(target_store)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 17 18 19 20 21 22 23 24 25 26 27 28 29 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 47 48 49 50 51 52 53 54 55 56 57 58 59 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61 62 63 64 65 66 67 68 69 70 71 72 73 74 75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76 77 78 79 80 81 82 83 84 85 86 87 88 89 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 91  92  93  94  95  96  97  98  99 100 101 102 103 104 105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106 107 108 109 110 111 112 113 114 115 116 117 118 119 120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121 122 123 124 125 126 127 128 129 130 131 132 133 134 135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136 137 138 139 140 141 142 143 144 145 146 147 148 149 150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151 152 153 154 155 156 157 158 159 160 161 162 163 164 165]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "maca_flow.run(parameters=run_hyperparameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
