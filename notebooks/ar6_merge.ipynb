{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a5d0e-6a8f-41aa-adc0-9f0c19e8dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2bf37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = 366  # number of time steps to load/process\n",
    "chunk_size = 48  # x/y chunk size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4198fb",
   "metadata": {},
   "source": [
    "## Generate example ar6 regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1dfab-bcb7-4ffa-97b7-2c823c5c02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(\n",
    "    'az://training/ERA5_daily/2000/', storage_options={'account_name': 'cmip6downscaling'}\n",
    ").head(time=ntime)\n",
    "mask = regionmask.defined_regions.ar6.land.mask(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3769b-d8b3-4d94-84c0-a12108d64c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into regions\n",
    "\n",
    "pieces = {}\n",
    "\n",
    "for key, group in ds['tasmax'].groupby(mask):\n",
    "    pieces[key] = group.unstack('stacked_lat_lon')\n",
    "\n",
    "# Save pieces\n",
    "\n",
    "# for key, group in pieces.items():\n",
    "#     group.to_dataset(name='tasmax').chunk({'time': -1, 'lat': 48, 'lon': 48}).to_zarr(f'az://scratch/regions/{key}.zarr', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023b0f9-9cc7-430a-8c63-29ea7cc33537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next:\n",
    "# - given a dictionary of xarray datasets from the ar6 regions, merge into a single dataset\n",
    "# - things to consider:\n",
    "#   - memory use\n",
    "#   - overlapping bounds\n",
    "#   - wrapped coordinates (for example, region `1` will not plot due to unsorted coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c842f",
   "metadata": {},
   "source": [
    "## Generate a template for merged output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.arange(0, 360, 0.25)\n",
    "lat = np.flip(np.arange(-90, 90.25, 0.25))\n",
    "time = pd.date_range(\"2000-01-01\", periods=ntime)\n",
    "\n",
    "template = xr.Dataset(\n",
    "    {\n",
    "        \"tasmax\": (\n",
    "            ('time', 'lat', 'lon'),\n",
    "            np.full((len(time), len(lat), len(lon)), fill_value=np.nan, dtype=np.single),\n",
    "        )\n",
    "    },\n",
    "    coords={\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"time\": time,\n",
    "    },\n",
    ")\n",
    "template.chunk({'lon': chunk_size, 'lat': chunk_size, 'time': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask with ar6 regions, replacing nan with 46 for 8-bit representation\n",
    "mask = regionmask.defined_regions.ar6.land.mask(template).fillna(46).astype(np.byte)\n",
    "mask = mask.chunk({'lon': chunk_size, 'lat': chunk_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a572d5",
   "metadata": {},
   "source": [
    "## Merge using manual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f343ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'az://scratch/merged_regions_slow.zarr'\n",
    "# Even though the template is chunked, specifying encoding here seems necessary to get the expected chunking in the final product\n",
    "template.to_zarr(path, compute=False, mode=\"w\", encoding={\"tasmax\": {\"chunks\": [-1, 48, 48]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abd1585",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed()\n",
    "def merge_block_to_zarr(mask, path, *, xslice, yslice):\n",
    "    \"\"\"\n",
    "    Find ar6 regions in each block, merge and reindex, write to zarr\n",
    "    \"\"\"\n",
    "    components = pd.unique(mask.values.ravel())\n",
    "    components = components[components <= 45]\n",
    "    if components.size > 0:\n",
    "        merged = (\n",
    "            xr.merge(\n",
    "                (\n",
    "                    xr.open_zarr(\n",
    "                        f'az://scratch/regions/{ind}.0.zarr'\n",
    "                    )  # Add .0 because subsets were created with mask as float dtypes\n",
    "                    .where(mask.isin(ind), drop=True)\n",
    "                    .sortby([\"lon\", \"lat\"])\n",
    "                    for ind in components\n",
    "                )\n",
    "            )\n",
    "            .reindex_like(mask)\n",
    "            .sortby(\"lat\", ascending=False)\n",
    "        ).compute()\n",
    "        return merged.to_zarr(\n",
    "            path,\n",
    "            region={'lat': yslice, 'lon': xslice, 'time': slice(0, merged.sizes['time'])},\n",
    "            mode=\"r+\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Iterate over chuncks and merge pieces within each chunk\n",
    "n_chunk_per_block = 3\n",
    "block_size = chunk_size * n_chunk_per_block\n",
    "# Iterate over chuncks and merge pieces within each chunk\n",
    "total = []\n",
    "for ilon in range(0, mask.sizes['lon'], block_size):\n",
    "    if ilon <= mask.sizes['lon'] - block_size:\n",
    "        xslice = slice(ilon, ilon + block_size)\n",
    "    else:\n",
    "        xslice = slice(ilon, mask.sizes['lon'])\n",
    "    for ilat in range(0, mask.sizes['lat'], block_size):\n",
    "        if ilat <= mask.sizes['lat'] - block_size:\n",
    "            yslice = slice(ilat, ilat + block_size)\n",
    "        else:\n",
    "            yslice = slice(ilat, mask.sizes['lat'])\n",
    "        total.append(\n",
    "            merge_block_to_zarr(\n",
    "                mask.isel(lon=xslice, lat=yslice), path, xslice=xslice, yslice=yslice\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482513eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = dask.compute(*total, scheduler='single-threaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac37e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example of the result\n",
    "data = xr.open_zarr(path)\n",
    "data['tasmax'].isel(time=0).plot()\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
