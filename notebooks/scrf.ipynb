{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef92da5-9e52-4238-9c95-3ae4f7c6b798",
   "metadata": {},
   "source": [
    "# Spatial-temporal Correlated Random Fields (SCRF)\n",
    "\n",
    "Author: Cindy Chiao  \n",
    "Date: 12/29/2021\n",
    "\n",
    "The purpose of this notebook is to generate spatially and temporally correlated random fields to be used to perturb the mean prediction result of GARD downscaling method. First, we use ERA5 observation data to find the appropriate length scales of correlation both spatially and temporally. Then, we use the correlation length scales to generate random fields covering the global domain in the resolution of ERA5. The package [gstools](https://geostat-framework.readthedocs.io/projects/gstools/en/stable/#pip) is used heavily in this process. A SCRF is generated for precipitation and another for temperature (will be used to perturb both tmin and tmax prediction result). \n",
    "\n",
    "Ideally, the entire available observation time series of the global domain would be used in determining the correlation length scales, and the SCRF of the entire future prediction period would be generated as one contiguous dataset. However, this proves to be prohibitive in terms of computation time due to the single threaded nature of the gstools algorithm. Thus, random subsamples of the observation time series were used to find the correlation length, and the SCRF was generated in 10 year long chunks. \n",
    "\n",
    "To find a representative spatial correlation length, we calculate the average spatial correlation lengths of 100 20x20 degree maps of 365 day time series. The 20x20 degree maps are constrained to areas of the globe that contain major landmass, avoiding the areas where it's majority ocean. \n",
    "\n",
    "To find a representative temporal correlation length, we use 10,000 samples of 365 day time series, again constrained to the areas containing major landmass. \n",
    "\n",
    "The spatial/temporal length scales for tmin and tmax are then averaged to be the length scale used to generate SCRF for temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49defb15-ec4d-4c2f-900c-8a506b5f76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c2d72b-e1e8-41fb-9e3c-46c74e523c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random \n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gstools as gs\n",
    "from cmip6_downscaling.workflows.paths import make_scrf_path\n",
    "from cmip6_downscaling.methods.gard import generate_scrf\n",
    "from cmip6_downscaling.data.observations import get_obs\n",
    "\n",
    "random.seed(20211228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a833741f-09c6-48ba-bb89-1d737d3b5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from carbonplan_trace.tiles import tiles\n",
    "from carbonplan_trace.v1 import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b61376-1c7f-471d-8867-15e77b3d63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask\n",
    "# from dask.distributed import Client\n",
    "# from dask_gateway import Gateway\n",
    "\n",
    "# client = Client(n_workers=8)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da694c9-19e5-4b66-9475-fe8bbb2e6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all 20x20 degree tiles that covers at least one 10x10 degree tile that has major land mass \n",
    "\n",
    "expanded_tiles = []\n",
    "for tile in tiles:\n",
    "    lat, lon = utils.get_lat_lon_tags_from_tile_path(tile)\n",
    "    min_lat, max_lat, min_lon, max_lon = utils.parse_bounding_box_from_lat_lon_tags(lat, lon)\n",
    "    \n",
    "    for i in [-1, 0]:\n",
    "        for j in [-1, 0]: \n",
    "            lat_tag, lon_tag = utils.get_lat_lon_tags_from_bounding_box(max_lat + (i * 10.), min_lon + (j * 10.))\n",
    "            expanded_tiles.append(f'{lat_tag}_{lon_tag}')\n",
    "            \n",
    "expanded_tiles = list(set(expanded_tiles))\n",
    "expanded_tiles = [t for t in expanded_tiles if '190W' not in t and '170E' not in t and '80N' not in t and '80S' not in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e34a58-fa62-401d-a89a-4f66bbc1f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_long3_to_long1(long3):\n",
    "    # see https://confluence.ecmwf.int/pages/viewpage.action?pageId=149337515\n",
    "    long1 = (long3 + 180) % 360 - 180\n",
    "    return long1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbc6f6d5-4c68-40b6-959f-7cb6b148b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['tasmax', 'tasmin', 'pr']\n",
    "seasonality_period = 31\n",
    "temporal_scaler = 1000.0\n",
    "\n",
    "sample_length_spatial = 365\n",
    "n_tiles = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7cbaa5-0e98-4f3c-9df0-506de02a062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dask.delayed\n",
    "def get_spatial_length(data):\n",
    "    fields = data.values\n",
    "    bin_center, gamma = gs.vario_estimate(\n",
    "        pos=(data.lon.values, data.lat.values),\n",
    "        field=fields,\n",
    "        latlon=True,\n",
    "        mesh_type='structured',\n",
    "    )\n",
    "    spatial = gs.Gaussian(dim=2, latlon=True, rescale=gs.EARTH_RADIUS)\n",
    "    spatial.fit_variogram(bin_center, gamma, sill=np.mean(np.var(fields, axis=(1, 2))))\n",
    "\n",
    "    return spatial.len_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486a486-f6a5-4cf7-8ee4-93375e18fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20S_180W 750.0602456090388\n",
      "70N_130W 382.7677229207885\n",
      "40N_070E 185.30041218869619\n",
      "20N_180W 733.3803737163283\n",
      "10N_060W 418.1033542994744\n",
      "20S_150E 722.0843982836062\n",
      "00N_160E 426.1326591106939\n",
      "50N_130W 392.8407718936695\n",
      "30N_020W 468.6199865577482\n",
      "50N_060W 448.31084414011957\n",
      "40S_020E 671.4496788688949\n",
      "50N_160E 786.4614176640292\n",
      "50N_150E 618.41025516108\n",
      "70N_170W 573.4163162251859\n",
      "30S_070W 375.12818399646466\n",
      "60N_150W 537.6277751057377\n",
      "50S_090W 326.76618911042567\n",
      "50N_020W 750.4098250287385\n",
      "40N_120W 307.8023834012744\n",
      "60S_070W 385.54188398585444\n",
      "30N_070E 205.73399303484172\n",
      "60S_060W 485.8036001672669\n",
      "20S_050W 460.640728202314\n",
      "30N_100E 214.00649059407667\n",
      "50N_070E 215.79855290959267\n",
      "70N_110E 313.25745563890945\n",
      "60N_100W 121.8317451045359\n",
      "20N_020W 477.6220207953892\n",
      "70N_100E 247.0252212758937\n",
      "60N_170W 569.4045193422498\n",
      "10N_060E 156.0500855767473\n",
      "70N_070W 410.0064253119047\n",
      "40S_160E 502.3985456412047\n",
      "60N_010E 654.4831836710368\n",
      "40N_040E 516.2511753496241\n",
      "30S_050E 425.6621742255346\n",
      "10S_040W 509.932309095416\n",
      "50S_140E 631.0558256649064\n",
      "70N_140E 494.02286949232445\n",
      "70N_130E 436.1418610884951\n",
      "60N_030E 514.4814535823068\n",
      "10S_000E 478.90061926383714\n",
      "70N_100W 103.82360540818695\n",
      "30N_020E 577.130661601149\n",
      "20S_070W 346.77546509129246\n",
      "10S_150E 549.5424797560165\n",
      "60S_090W 244.77289416915906\n",
      "20N_000E 664.3590645888198\n",
      "00N_080W 211.7704274889637\n",
      "50S_070W 449.78210305183467\n",
      "20N_030W 496.8553004115663\n",
      "30N_110W 217.73978262234465\n",
      "00N_110W 113.07768939638116\n",
      "60N_130E 467.56511763909185\n",
      "20N_090W 539.2015368203269\n",
      "00N_000E 499.4066628558288\n",
      "10N_070E 135.5554563054838\n",
      "20N_080W 261.47373867219466\n",
      "10S_160E 609.9303554131534\n",
      "20N_110E 327.6665607389824\n",
      "40N_090E 184.17597193031972\n",
      "30S_040E 506.6021808488878\n",
      "70N_070E 191.3481767895423\n",
      "50N_130E 483.87235676330084\n",
      "00N_100E 114.32927470153561\n",
      "50N_060E 282.37413416843776\n",
      "10S_070W 370.3781079777422\n",
      "60N_150E 601.3383380189395\n",
      "00N_140E 386.12501622785413\n",
      "10S_100W 116.85825490978229\n",
      "40N_020E 592.3947422511488\n",
      "10S_080W 288.13587382631795\n",
      "20S_080W 390.6786829736973\n",
      "70N_090W 251.5356685629105\n",
      "60N_030W 705.1409829285476\n",
      "10N_020E 516.5222633003087\n",
      "20N_060W 478.3608495625322\n",
      "30N_080E 99.82038497860589\n",
      "50N_140E 652.4042601542639\n",
      "10N_040E 423.5110203953639\n"
     ]
    }
   ],
   "source": [
    "for v in variables:\n",
    "    print(v)\n",
    "    data = get_obs(\n",
    "        obs='ERA5',\n",
    "        train_period_start=1980,\n",
    "        train_period_end=2020,\n",
    "        variables=v,\n",
    "        chunking_approach=None,\n",
    "    )[v]\n",
    "    \n",
    "    # go from 0-360 to -180-180 longitude \n",
    "    data['lon'] = convert_long3_to_long1(data.lon)\n",
    "    data = data.reindex(lon=sorted(data.lon.values))\n",
    "    \n",
    "    # detrend \n",
    "    seasonality = (\n",
    "        data.rolling({'time': seasonality_period}, center=True, min_periods=1)\n",
    "        .mean()\n",
    "        .groupby('time.dayofyear')\n",
    "        .mean()\n",
    "    )\n",
    "    detrended = data.groupby(\"time.dayofyear\") - seasonality\n",
    "    detrended = detrended.transpose('time', 'lon', 'lat')\n",
    "    possible_time_starts = len(detrended.time) - sample_length_spatial\n",
    "\n",
    "    spatial_length_scale = []\n",
    "    chosen_tiles = random.sample(expanded_tiles, k=n_tiles)\n",
    "    for tile in chosen_tiles:\n",
    "        lat, lon = utils.get_lat_lon_tags_from_tile_path(tile)\n",
    "        min_lat, max_lat, min_lon, max_lon = utils.parse_bounding_box_from_lat_lon_tags(lat, lon)\n",
    "        max_lat += 10\n",
    "        max_lon += 10 \n",
    "        t = random.randint(a=0, b=possible_time_starts)\n",
    "        sub = detrended.sel(lat=slice(max_lat, min_lat), lon=slice(min_lon, max_lon)).isel(time=slice(t, t+sample_length_spatial))\n",
    "        # spatial_length_scale.append(client.persist(get_spatial_length(sub), retries=1))\n",
    "        l = get_spatial_length(sub)\n",
    "        spatial_length_scale.append(l)\n",
    "        print(tile, l)\n",
    "\n",
    "    df = pd.DataFrame({'tile': expanded_tiles, 'spatial_length_scale': spatial_length_scale})\n",
    "    df.to_csv(f'{v}_spatial_length_scale.csv')\n",
    "    print(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3343d4e2-066d-4381-bf25-49f41d1a9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in variables:\n",
    "    print(v)\n",
    "    data = get_obs(\n",
    "        obs='ERA5',\n",
    "        train_period_start=1980,\n",
    "        train_period_end=2020,\n",
    "        variables=v,\n",
    "        chunking_approach=None,\n",
    "    )[v]\n",
    "    \n",
    "    # go from 0-360 to -180-180 longitude \n",
    "    data['lon'] = convert_long3_to_long1(data.lon)\n",
    "    data = data.reindex(lon=sorted(data.lon.values))\n",
    "    \n",
    "    # detrend \n",
    "    seasonality = (\n",
    "        data.rolling({'time': seasonality_period}, center=True, min_periods=1)\n",
    "        .mean()\n",
    "        .groupby('time.dayofyear')\n",
    "        .mean()\n",
    "    )\n",
    "    detrended = data.groupby(\"time.dayofyear\") - seasonality\n",
    "    detrended = detrended.transpose('time', 'lon', 'lat')\n",
    "    possible_time_starts = len(detrended.time) - sample_length_spatial\n",
    "\n",
    "    spatial_length_scale = []\n",
    "    chosen_tiles = random.sample(expanded_tiles, k=n_tiles)\n",
    "    for tile in chosen_tiles:\n",
    "        lat, lon = utils.get_lat_lon_tags_from_tile_path(tile)\n",
    "        min_lat, max_lat, min_lon, max_lon = utils.parse_bounding_box_from_lat_lon_tags(lat, lon)\n",
    "        max_lat += 10\n",
    "        max_lon += 10 \n",
    "        t = random.randint(a=0, b=possible_time_starts)\n",
    "        sub = detrended.sel(lat=slice(max_lat, min_lat), lon=slice(min_lon, max_lon)).isel(time=slice(t, t+sample_length_spatial))\n",
    "        # spatial_length_scale.append(client.persist(get_spatial_length(sub), retries=1))\n",
    "        l = get_spatial_length(sub)\n",
    "        spatial_length_scale.append(l)\n",
    "        print(tile, l)\n",
    "\n",
    "    df = pd.DataFrame({'tile': expanded_tiles, 'spatial_length_scale': spatial_length_scale})\n",
    "    df.to_csv(f'{v}_spatial_length_scale.csv')\n",
    "    print(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03d395a-bb8f-4246-b48b-52f0be7333cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields = []\n",
    "# day_in_year = 365\n",
    "# for yr, group in detrended.groupby('time.year'):\n",
    "#     # TODO: this is a very long list for a large domain, perhaps need random sampling\n",
    "#     v = (\n",
    "#         group.isel(time=slice(0, day_in_year))\n",
    "#         .stack(point=['lat', 'lon'])\n",
    "#         .transpose('point', 'time')\n",
    "#         .values\n",
    "#     )\n",
    "#     fields.extend(list(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73999349-607f-4725-87a8-8f5cb7fc1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.var(fields, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f9ee7d-bf84-4e26-a984-4b9f648a8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    scrf = generate_scrf(\n",
    "        data=ds_obs,\n",
    "        label=v,\n",
    "        n_timepoints=365*30+8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b3d713-97b4-427c-9f2f-935657fbb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 500\n",
    "ts = 10\n",
    "\n",
    "model = gs.Gaussian(dim=3, var=1.0, len_scale=[ss, ss, ts])\n",
    "srf = gs.SRF(model, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a65927-941e-49e9-bd28-318520af3847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.33059689203898\n"
     ]
    }
   ],
   "source": [
    "step = 25\n",
    "nx = 100\n",
    "ny = 100\n",
    "nt = 365*30+8\n",
    "\n",
    "x = np.arange(0, nx*step, step)\n",
    "y = np.arange(0, ny*step, step)\n",
    "t = np.arange(0, nt)\n",
    "\n",
    "t1 = time.time()\n",
    "field = srf.structured((x, y, t))\n",
    "t2 = time.time()\n",
    "\n",
    "print((t2-t1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9016463-a3d8-4333-a9fb-d6ba7ce5c0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109580000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 25\n",
    "nx = 100\n",
    "ny = 100\n",
    "nt = 365*30+8\n",
    "\n",
    "x = np.arange(0, nx*step, step)\n",
    "y = np.arange(0, ny*step, step)\n",
    "t = np.arange(0, nt)\n",
    "\n",
    "len(x) * len(y) * len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a802e03f-3ce5-4d93-aaa9-85b6befa5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217.89220894575118\n"
     ]
    }
   ],
   "source": [
    "# 10 year chunks \n",
    "# \n",
    "\n",
    "step = 25\n",
    "nx = 360*4\n",
    "ny = 180*4\n",
    "nt = 365\n",
    "\n",
    "x = np.arange(0, nx*step, step)\n",
    "y = np.arange(0, ny*step, step)\n",
    "t = np.arange(0, nt)\n",
    "\n",
    "t1 = time.time()\n",
    "field = srf.structured((x, y, t))\n",
    "t2 = time.time()\n",
    "\n",
    "print((t2-t1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15bd02d5-4897-4bd0-b57b-9224706baab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b7111-ac54-4118-ac98-4ab087caab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in np.arange(30):\n",
    "    i = random.randint(0, 365)\n",
    "    plt.imshow(field[:, :, _])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# size = 720*16//9, 720\n",
    "# duration = 2\n",
    "# fps = 25\n",
    "# out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (size[1], size[0]), False)\n",
    "# for _ in range(fps * duration):\n",
    "#     data = np.random.randint(0, 256, size, dtype='uint8')\n",
    "#     out.write(data)\n",
    "# out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0640bf65-2ee6-4546-b70d-e0b5dfc25543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378432000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 25\n",
    "nx = 360*4\n",
    "ny = 180*4\n",
    "nt = 365\n",
    "\n",
    "x = np.arange(0, nx*step, step)\n",
    "y = np.arange(0, ny*step, step)\n",
    "t = np.arange(0, nt)\n",
    "\n",
    "len(x) * len(y) * len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04577b38-e612-4da7-8fb4-6ca438eeb4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.453476911845227"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "378432000 / 109580000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c96045f-89ec-42ef-a441-571f0d78b521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4957503988475507"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "217.89220894575118 / 62.33059689203898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b7a7e5-fcc3-4e24-9bbc-efb6d929f76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108.94610447287559"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "217.89220894575118 * 30 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b51446-25c2-43ac-8522-a0ef9d8bfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.DataArray(\n",
    "    np.random.rand(360*4, 180*4, 365*30+8),\n",
    "    dims=['lon', 'lat', 'time'],\n",
    "    coords=[np.arange(360*4), np.arange(180*4), np.arange(365*30+8)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de09a39-97ae-4cf9-a166-d30d40b9e21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.8900352"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04011e-3870-4f4f-8a82-efe3fecd8b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
