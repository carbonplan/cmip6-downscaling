{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef92da5-9e52-4238-9c95-3ae4f7c6b798",
   "metadata": {},
   "source": [
    "# Spatial-temporal Correlated Random Fields (SCRF)\n",
    "\n",
    "Author: Cindy Chiao  \n",
    "Date: 02/01/2022\n",
    "\n",
    "The purpose of this notebook is to generate spatially and temporally correlated\n",
    "random fields to be used to perturb the mean prediction result of GARD\n",
    "downscaling method. First, we use ERA5 observation data to find the appropriate\n",
    "length scales of correlation both spatially and temporally. Then, we use the\n",
    "correlation length scales to generate random fields covering the global domain\n",
    "in the resolution of ERA5. Finally, we inspect the output to make sure the\n",
    "random fields meet the input spec we provided. The package\n",
    "[gstools](https://geostat-framework.readthedocs.io/projects/gstools/en/stable/#pip)\n",
    "is used heavily in this process. A SCRF is generated for precipitation and\n",
    "another for temperature (will be used to perturb both tmin and tmax prediction\n",
    "result).\n",
    "\n",
    "Ideally, the entire available observation time series of the global domain would\n",
    "be used in determining the correlation length scales, and the SCRF of the entire\n",
    "future prediction period would be generated as one contiguous dataset. However,\n",
    "this proves to be prohibitive in terms of computation time due to the single\n",
    "threaded nature of the gstools algorithm. Thus, random subsamples of the\n",
    "observation time series were used to find the correlation length, and the SCRF\n",
    "was generated in decade (10 year) long chunks.\n",
    "\n",
    "### 1. Find correlation length scale\n",
    "\n",
    "- To find a representative spatial correlation length, we calculate the average\n",
    "  spatial correlation lengths of 100 20x20 degree maps of 365 day time series.\n",
    "  The 20x20 degree maps are constrained to areas of the globe that contain major\n",
    "  landmass, avoiding the areas where it's majority ocean.\n",
    "- To find a representative temporal correlation length, we use 10,000 samples of\n",
    "  365 day time series, again constrained to the areas containing major landmass.\n",
    "- We use the `latlon=True` and `rescale=gs.EARTH_RADIUS` options in `gstools` to\n",
    "  obtain the spatial length scale. The latlon=True option requires the input to\n",
    "  be only 2D (ie. we can't get spatial and temporal scales in the same function\n",
    "  call) and gives us the spatial length scale in km. The correlation length\n",
    "  scale is assumed to be the same in both x/y directions.\n",
    "\n",
    "### 2. Generate random fields\n",
    "\n",
    "- The spatial/temporal length scales for tmin and tmax are then averaged to be\n",
    "  the length scale used to generate SCRF for temperature. The same random field\n",
    "  is then saved for both tmax and tmin such that the same random perturbation\n",
    "  will be applied to tmax/tmin.\n",
    "- While we obtained the spatial and temporal correlation length scales\n",
    "  separately, the random fields have to be generated with spatial and temporal\n",
    "  correlations in the same operation. However, the `latlon` option in `gstools`\n",
    "  only allows generation of 2D fields (without temporal). Thus, we generate the\n",
    "  spatially and temporally correlated random fields we need in a projected space\n",
    "  (the Miller projection is used here after inspecting the results of a few\n",
    "  projections).\n",
    "- Due to memory constraints, the random fields are first generated in 10 year\n",
    "  chunks in a 180x360 grid (roughly 1 degree = 100km) and interpolated to the\n",
    "  full 721x1440 grid of the observation dataset. For comparison, the spatial\n",
    "  correlation length scale is on the order of 400km.\n",
    "\n",
    "### 3. Verify output\n",
    "\n",
    "- We inspected the output to make sure that the random fields of each decade are\n",
    "  different from each other, that the random fields for precip and temp are\n",
    "  different from each other, and that the random fields for tmax and tmin are\n",
    "  identical.\n",
    "- We then plotted the random fields both in flat maps and on spheres to inspect\n",
    "  any distortion caused by the projection. The Miller projection doesn't cause\n",
    "  any directional distortion based on visual inspection; however, the spatial\n",
    "  scale of correlation appears to be larger near the equator and smaller near\n",
    "  the poles.\n",
    "- The average spatial length scale of the output is lower than the input by\n",
    "  around 25% (input = ~400km, output = ~300km). The temporal scale of the output\n",
    "  roughly matches with the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49defb15-ec4d-4c2f-900c-8a506b5f76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2d72b-e1e8-41fb-9e3c-46c74e523c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gstools as gs\n",
    "import rioxarray\n",
    "import xesmf as xe\n",
    "\n",
    "# from cmip6_downscaling.workflows.paths import make_scrf_path\n",
    "from cmip6_downscaling.data.observations import get_obs\n",
    "\n",
    "random.seed(20211228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833741f-09c6-48ba-bb89-1d737d3b5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from carbonplan_trace.tiles import tiles\n",
    "from carbonplan_trace.v1 import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdc3e9-d724-4eaa-a917-1db1888cdcdf",
   "metadata": {},
   "source": [
    "## Finding correlation length scales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da694c9-19e5-4b66-9475-fe8bbb2e6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all 20x20 degree tiles that covers at least one 10x10 degree tile that has major land mass\n",
    "\n",
    "expanded_tiles = []\n",
    "for tile in tiles:\n",
    "    lat, lon = utils.get_lat_lon_tags_from_tile_path(tile)\n",
    "    (\n",
    "        min_lat,\n",
    "        max_lat,\n",
    "        min_lon,\n",
    "        max_lon,\n",
    "    ) = utils.parse_bounding_box_from_lat_lon_tags(lat, lon)\n",
    "\n",
    "    for i in [-1, 0]:\n",
    "        for j in [-1, 0]:\n",
    "            lat_tag, lon_tag = utils.get_lat_lon_tags_from_bounding_box(\n",
    "                max_lat + (i * 10.0), min_lon + (j * 10.0)\n",
    "            )\n",
    "            expanded_tiles.append(f\"{lat_tag}_{lon_tag}\")\n",
    "\n",
    "expanded_tiles = list(set(expanded_tiles))\n",
    "expanded_tiles = [\n",
    "    t\n",
    "    for t in expanded_tiles\n",
    "    if \"190W\" not in t and \"170E\" not in t and \"80N\" not in t and \"80S\" not in t\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6f6d5-4c68-40b6-959f-7cb6b148b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"tasmax\", \"tasmin\", \"pr\"]\n",
    "seasonality_period = 31\n",
    "\n",
    "sample_length = 365\n",
    "n_samples_temporal = 10000\n",
    "n_tiles_spatial = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7cbaa5-0e98-4f3c-9df0-506de02a062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_length(data):\n",
    "    fields = data.values\n",
    "    bin_center, gamma = gs.vario_estimate(\n",
    "        pos=(data.lon.values, data.lat.values),\n",
    "        field=fields,\n",
    "        latlon=True,\n",
    "        mesh_type=\"structured\",\n",
    "    )\n",
    "    spatial = gs.Gaussian(dim=2, latlon=True, rescale=gs.EARTH_RADIUS)\n",
    "    spatial.fit_variogram(bin_center, gamma, sill=np.mean(np.var(fields, axis=(1, 2))))\n",
    "\n",
    "    return spatial.len_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486a486-f6a5-4cf7-8ee4-93375e18fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial length scale\n",
    "\n",
    "for v in variables:\n",
    "    print(v)\n",
    "    fname = f\"{v}_spatial_length_scale.csv\"\n",
    "    if os.path.exists(fname):\n",
    "        df = pd.read_csv(fname)\n",
    "        df = df.loc[df.spatial_length_scale > 1]\n",
    "        print(df.spatial_length_scale.mean())\n",
    "    else:\n",
    "        data = get_obs(\n",
    "            obs=\"ERA5\",\n",
    "            train_period_start=1980,\n",
    "            train_period_end=2020,\n",
    "            variables=v,\n",
    "            chunking_approach=None,\n",
    "        )[v]\n",
    "\n",
    "        if v == \"pr\":\n",
    "            data = data * 1e6\n",
    "\n",
    "        # detrend\n",
    "        seasonality = (\n",
    "            data.rolling({\"time\": seasonality_period}, center=True, min_periods=1)\n",
    "            .mean()\n",
    "            .groupby(\"time.dayofyear\")\n",
    "            .mean()\n",
    "        )\n",
    "        detrended = data.groupby(\"time.dayofyear\") - seasonality\n",
    "        detrended = detrended.transpose(\"time\", \"lon\", \"lat\")\n",
    "        possible_time_starts = len(detrended.time) - sample_length\n",
    "\n",
    "        spatial_length_scale = []\n",
    "        chosen_tiles = random.sample(expanded_tiles, k=n_tiles_spatial)\n",
    "        for tile in chosen_tiles:\n",
    "            lat, lon = utils.get_lat_lon_tags_from_tile_path(tile)\n",
    "            (\n",
    "                min_lat,\n",
    "                max_lat,\n",
    "                min_lon,\n",
    "                max_lon,\n",
    "            ) = utils.parse_bounding_box_from_lat_lon_tags(lat, lon)\n",
    "            max_lat += 10\n",
    "            max_lon += 10\n",
    "            t = random.randint(a=0, b=possible_time_starts)\n",
    "            sub = detrended.sel(lat=slice(max_lat, min_lat), lon=slice(min_lon, max_lon)).isel(\n",
    "                time=slice(t, t + sample_length)\n",
    "            )\n",
    "            # spatial_length_scale.append(client.persist(get_spatial_length(sub), retries=1))\n",
    "            l = get_spatial_length(sub)\n",
    "            spatial_length_scale.append(l)\n",
    "            print(tile, l)\n",
    "\n",
    "        df = pd.DataFrame({\"tile\": chosen_tiles, \"spatial_length_scale\": spatial_length_scale})\n",
    "        df.to_csv(f\"{v}_spatial_length_scale.csv\")\n",
    "        df = df.loc[df.spatial_length_scale > 1]\n",
    "        print(df.spatial_length_scale.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f570b-4a3e-49fa-b68a-47981b0d3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length = 100\n",
    "temporal_scaler = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343d4e2-066d-4381-bf25-49f41d1a9e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temporal length scale\n",
    "for v in variables:\n",
    "    print(v)\n",
    "    data = get_obs(\n",
    "        obs=\"ERA5\",\n",
    "        train_period_start=1980,\n",
    "        train_period_end=2020,\n",
    "        variables=v,\n",
    "        chunking_approach=None,\n",
    "    )[v]\n",
    "\n",
    "    if v == \"pr\":\n",
    "        data = data * 1e3\n",
    "\n",
    "    # go from 0-360 to -180-180 longitude\n",
    "    data[\"lon\"] = convert_long3_to_long1(data.lon)\n",
    "    data = data.reindex(lon=sorted(data.lon.values))\n",
    "\n",
    "    # detrend\n",
    "    print(\"detrending\")\n",
    "    seasonality = (\n",
    "        data.rolling({\"time\": seasonality_period}, center=True, min_periods=1)\n",
    "        .mean()\n",
    "        .groupby(\"time.dayofyear\")\n",
    "        .mean()\n",
    "    )\n",
    "    detrended = data.groupby(\"time.dayofyear\") - seasonality\n",
    "    detrended = detrended.transpose(\"time\", \"lon\", \"lat\")\n",
    "    possible_time_starts = len(detrended.time) - sample_length\n",
    "    detrended = detrended.stack(point=[\"lat\", \"lon\"])\n",
    "\n",
    "    print(\"building samples\")\n",
    "    points = []\n",
    "\n",
    "    chosen_tiles = random.choices(tiles, k=n_samples_temporal)\n",
    "    ii = random.choices(np.arange(40), k=n_samples_temporal)\n",
    "    jj = random.choices(np.arange(40), k=n_samples_temporal)\n",
    "\n",
    "    lat_lon_tags = [utils.get_lat_lon_tags_from_tile_path(tile) for tile in chosen_tiles]\n",
    "    bounding_boxes = [\n",
    "        utils.parse_bounding_box_from_lat_lon_tags(lat, lon) for lat, lon in lat_lon_tags\n",
    "    ]\n",
    "\n",
    "    for bounding_box, i, j in zip(bounding_boxes, ii, jj):\n",
    "        min_lat, max_lat, min_lon, max_lon = bounding_box\n",
    "        lat = min_lat + i * 0.25\n",
    "        lon = min_lon + j * 0.25\n",
    "        points.append((lat, lon))\n",
    "\n",
    "    points.sort(key=lambda u: u[0])\n",
    "    sub = detrended.sel(point=points).load()\n",
    "\n",
    "    t_starts = np.array(random.choices(np.arange(possible_time_starts), k=n_samples_temporal))\n",
    "    t_ends = t_starts + sample_length\n",
    "\n",
    "    fields = []\n",
    "    for i, (start, end) in enumerate(zip(t_starts, t_ends)):\n",
    "        f = sub.isel(point=i, time=slice(start, end)).values\n",
    "        fields.append(f)\n",
    "\n",
    "    print(\"finding correlation length\")\n",
    "    t = np.arange(sample_length) / temporal_scaler\n",
    "    bin_center, gamma = gs.vario_estimate(pos=t, field=fields, mesh_type=\"structured\")\n",
    "    temporal = gs.Gaussian(dim=1)\n",
    "    temporal.fit_variogram(bin_center, gamma, sill=np.mean(np.var(fields, axis=1)))\n",
    "\n",
    "    print(v, temporal.len_scale * temporal_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b9094-a993-43c8-9f4b-4a28fac8a325",
   "metadata": {},
   "source": [
    "## Generating SRCF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149e532-464a-4bdc-a041-c81eddf9b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in units of km\n",
    "spatial_scales = {\n",
    "    \"tasmax\": 437.36955028922074,\n",
    "    \"tasmin\": 419.73912697665384,\n",
    "    \"pr\": 404.29331338341586,\n",
    "}\n",
    "\n",
    "# in units of day\n",
    "temporal_scales = {\n",
    "    \"tasmax\": 3.725572253986237,\n",
    "    \"tasmin\": 3.9400152223556937,\n",
    "    \"pr\": 2.0457947933307676,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6204cf5-4d1c-4641-8363-1eedc6310722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "\n",
    "def make_scrf_path(\n",
    "    obs: str,\n",
    "    label: str,\n",
    "    start_year: str,\n",
    "    end_year: str,\n",
    "    **kwargs,\n",
    "):\n",
    "    return f\"scrf/{obs}_{label}_{start_year}_{end_year}.zarr\"\n",
    "    # return f\"scrf/{crs.split('=')[-1]}_test.zarr\"\n",
    "\n",
    "\n",
    "# @dask.delayed\n",
    "def generate_scrf(\n",
    "    variable,\n",
    "    spatial_scales,\n",
    "    temporal_scales,\n",
    "    start_year,\n",
    "    end_year,\n",
    "):\n",
    "    if variable == \"temp\":\n",
    "        path = make_scrf_path(\"ERA5\", \"tasmin\", start_year, end_year)\n",
    "        store = fsspec.get_mapper(f\"az://flow-outputs/intermediate/\" + path)\n",
    "    else:\n",
    "        path = make_scrf_path(\"ERA5\", \"pr\", start_year, end_year)\n",
    "        store = fsspec.get_mapper(f\"az://flow-outputs/intermediate/\" + path)\n",
    "\n",
    "    print(path)\n",
    "    if \".zmetadata\" in store:\n",
    "        return (\"skipping\", path)\n",
    "\n",
    "    # get the correct temporal and spatial scales to use\n",
    "    print(\"initializing model\")\n",
    "    if variable == \"temp\":\n",
    "        ss = np.round(np.mean([spatial_scales[\"tasmax\"], spatial_scales[\"tasmin\"]]), 1)\n",
    "        ts = np.round(np.mean([temporal_scales[\"tasmax\"], temporal_scales[\"tasmin\"]]), 1)\n",
    "        v = \"tasmax\"\n",
    "    elif variable == \"pr\":\n",
    "        ss = np.round(spatial_scales[\"pr\"], 1)\n",
    "        ts = np.round(temporal_scales[\"pr\"], 1)\n",
    "        v = \"pr\"\n",
    "\n",
    "    # initializing model\n",
    "    model = gs.Gaussian(dim=3, var=1.0, len_scale=[ss, ss, ts])\n",
    "    srf = gs.SRF(model, seed=int(start_year) + len(variable))\n",
    "\n",
    "    print(\"getting template\")\n",
    "    template = get_obs(\n",
    "        obs=\"ERA5\",\n",
    "        train_period_start=1980,\n",
    "        train_period_end=1980,\n",
    "        variables=v,\n",
    "        chunking_approach=None,\n",
    "    )[v].isel(time=0)\n",
    "    template = template.rename({\"lon\": \"x\", \"lat\": \"y\"})\n",
    "\n",
    "    # where miller projection comes into play\n",
    "    mill_template = xr.DataArray(\n",
    "        0,\n",
    "        dims=[\"x\", \"y\"],\n",
    "        coords=[\n",
    "            np.linspace(start=-20000000, stop=20000000, num=360),\n",
    "            np.linspace(start=-14000000, stop=14000000, num=181),\n",
    "        ],\n",
    "    )\n",
    "    mill_template = mill_template.rio.write_crs(\"+proj=mill\")\n",
    "\n",
    "    projected = template.rio.write_crs(\"EPSG:4326\").rio.reproject_match(mill_template)\n",
    "    # transform from m to km\n",
    "    x = np.round(projected.x.values / 1000.0, 2)\n",
    "    y = np.round(projected.y.values / 1000.0, 2)\n",
    "\n",
    "    # get number of days in the period\n",
    "    t = pd.date_range(start=f\"{start_year}-01-01\", end=f\"{end_year}-12-31\", freq=\"D\")\n",
    "    print(len(x), len(y), len(t))\n",
    "\n",
    "    print(\"generating field\")\n",
    "    # generate field\n",
    "    time = np.arange(len(t))\n",
    "    field = srf.structured((x, y, time))\n",
    "\n",
    "    print(\"making dataarray\")\n",
    "    field = xr.DataArray(\n",
    "        field,\n",
    "        dims=[\"x\", \"y\", \"time\"],\n",
    "        coords=[projected.x, projected.y, t],\n",
    "    ).rio.write_crs(\"+proj=mill\")\n",
    "\n",
    "    # reprojecting\n",
    "    print(\"reprojecting\")\n",
    "    field = field.transpose(\"time\", \"y\", \"x\").rio.reproject(\"EPSG:4326\")\n",
    "    field = field.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "    template = template.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "\n",
    "    # regridding\n",
    "    print(\"regridding\")\n",
    "    regridder = xe.Regridder(field, template, \"bilinear\", extrap_method=\"nearest_s2d\")\n",
    "    regridded_field = regridder(field)\n",
    "\n",
    "    print(\"saving\")\n",
    "    # save to file\n",
    "    if variable == \"temp\":\n",
    "        for v in [\"tasmax\", \"tasmin\"]:\n",
    "            path = make_scrf_path(\"ERA5\", v, start_year, end_year)\n",
    "            store = fsspec.get_mapper(\"az://flow-outputs/intermediate/\" + path)\n",
    "            regridded_field.to_dataset(name=\"scrf\").to_zarr(store, mode=\"w\", consolidated=True)\n",
    "    else:\n",
    "        path = make_scrf_path(\"ERA5\", \"pr\", start_year, end_year)\n",
    "        store = fsspec.get_mapper(\"az://flow-outputs/intermediate/\" + path)\n",
    "        regridded_field.to_dataset(name=\"scrf\").to_zarr(store, mode=\"w\", consolidated=True)\n",
    "\n",
    "    return (\"processed\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61ad51-deb2-4e76-9130-8ccf62cf3586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for variable in [\"temp\", \"pr\"]:\n",
    "    for start_year in np.arange(1981, 2100, 10):\n",
    "        end_year = str(start_year + 9)\n",
    "        start_year = str(start_year)\n",
    "        print(variable, start_year, end_year)\n",
    "\n",
    "        generate_scrf(\n",
    "            variable=variable,\n",
    "            spatial_scales=spatial_scales,\n",
    "            temporal_scales=temporal_scales,\n",
    "            start_year=start_year,\n",
    "            end_year=end_year,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebadadf-4a57-48d4-96fc-c7344135614b",
   "metadata": {},
   "source": [
    "# Validating correlation length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f48345-5c73-414e-a13b-311049b736cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the random field output\n",
    "# make sure the different decades are different\n",
    "# make sure precip is different from tmax, but tmax is the same as tmin\n",
    "time = 100\n",
    "\n",
    "ds1 = xr.open_zarr(\"az://flow-outputs/intermediate/scrf/ERA5_pr_2011_2020.zarr\").scrf.isel(\n",
    "    time=time\n",
    ")\n",
    "\n",
    "ds2 = xr.open_zarr(\"az://flow-outputs/intermediate/scrf/ERA5_pr_2021_2030.zarr\").scrf.isel(\n",
    "    time=time\n",
    ")\n",
    "\n",
    "ds3 = xr.open_zarr(\"az://flow-outputs/intermediate/scrf/ERA5_tasmax_2011_2020.zarr\").scrf.isel(\n",
    "    time=time\n",
    ")\n",
    "\n",
    "ds4 = xr.open_zarr(\"az://flow-outputs/intermediate/scrf/ERA5_tasmin_2011_2020.zarr\").scrf.isel(\n",
    "    time=time\n",
    ")\n",
    "\n",
    "ds1.plot(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569b1ef-bb4e-4aa5-969a-eac2bf4f544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds1 - ds2).plot(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15484952-4083-4514-b9e6-9d31849bcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds1 - ds3).plot(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d5ce4-67e8-4817-b14d-b7aaa5320681",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds3 - ds4).plot(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17773e4-4b05-4b72-ab14-96d80b010662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "\n",
    "def globe_plot(ds, lat=60, lon=0):\n",
    "    ds.plot(\n",
    "        subplot_kws=dict(projection=ccrs.Orthographic(lat, lon), facecolor=\"gray\"),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802ae6a-72d2-476e-ad34-178edec9e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "globe_plot(ds1, 60, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1dcf9-0a54-45ad-b676-98d84908138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "globe_plot(ds2, 60, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f34c3-534e-4d9a-8229-6da44ecd14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "globe_plot(ds1, 60, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed878bcf-ac01-4e59-a9cd-a9ca308eb160",
   "metadata": {},
   "outputs": [],
   "source": [
    "globe_plot(ds2, 60, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f770607-5748-4f87-9926-816d993fcb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spatial length -- 274km instead of 404km in input\n",
    "ds = xr.open_zarr(\"az://flow-outputs/intermediate/scrf/ERA5_pr_2011_2020.zarr\").scrf\n",
    "possible_time_starts = len(ds.time) - sample_length\n",
    "\n",
    "spatial_length_scale = []\n",
    "chosen_tiles = random.sample(expanded_tiles, k=n_tiles_spatial)\n",
    "for tile in chosen_tiles:\n",
    "    lat, lon = utils.get_lat_lon_tags_from_tile_path(tile)\n",
    "    (\n",
    "        min_lat,\n",
    "        max_lat,\n",
    "        min_lon,\n",
    "        max_lon,\n",
    "    ) = utils.parse_bounding_box_from_lat_lon_tags(lat, lon)\n",
    "    max_lat += 10\n",
    "    max_lon += 10\n",
    "    t = random.randint(a=0, b=possible_time_starts)\n",
    "    sub = ds.sel(lat=slice(max_lat, min_lat), lon=slice(min_lon, max_lon)).isel(\n",
    "        time=slice(t, t + sample_length)\n",
    "    )\n",
    "    l = get_spatial_length(sub)\n",
    "    spatial_length_scale.append(l)\n",
    "\n",
    "df = pd.DataFrame({\"tile\": chosen_tiles, \"spatial_length_scale\": spatial_length_scale})\n",
    "df = df.loc[df.spatial_length_scale > 1]\n",
    "print(df.spatial_length_scale.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39050caf-6d83-4c1b-8a4f-0cedbbcad46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal length scale --> 1.88 days instead of 2.05 days in input\n",
    "print(\"building samples\")\n",
    "points = []\n",
    "\n",
    "chosen_tiles = random.choices(tiles, k=n_samples_temporal)\n",
    "ii = random.choices(np.arange(40), k=n_samples_temporal)\n",
    "jj = random.choices(np.arange(40), k=n_samples_temporal)\n",
    "\n",
    "lat_lon_tags = [utils.get_lat_lon_tags_from_tile_path(tile) for tile in chosen_tiles]\n",
    "bounding_boxes = [utils.parse_bounding_box_from_lat_lon_tags(lat, lon) for lat, lon in lat_lon_tags]\n",
    "\n",
    "for bounding_box, i, j in zip(bounding_boxes, ii, jj):\n",
    "    min_lat, max_lat, min_lon, max_lon = bounding_box\n",
    "    lat = min_lat + i * 0.25\n",
    "    lon = min_lon + j * 0.25\n",
    "    points.append((lat, lon))\n",
    "\n",
    "points.sort(key=lambda u: u[0])\n",
    "sub = ds.stack(point=[\"lat\", \"lon\"]).sel(point=points).load()\n",
    "\n",
    "t_starts = np.array(random.choices(np.arange(possible_time_starts), k=n_samples_temporal))\n",
    "t_ends = t_starts + sample_length\n",
    "\n",
    "fields = []\n",
    "for i, (start, end) in enumerate(zip(t_starts, t_ends)):\n",
    "    f = sub.isel(point=i, time=slice(start, end)).values\n",
    "    fields.append(f)\n",
    "\n",
    "print(\"finding correlation length\")\n",
    "t = np.arange(sample_length) / temporal_scaler\n",
    "bin_center, gamma = gs.vario_estimate(pos=t, field=fields, mesh_type=\"structured\")\n",
    "temporal = gs.Gaussian(dim=1)\n",
    "temporal.fit_variogram(bin_center, gamma, sill=np.mean(np.var(fields, axis=1)))\n",
    "\n",
    "print(temporal.len_scale * temporal_scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
