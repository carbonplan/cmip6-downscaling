{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18602a55-b724-4dba-8df9-7f15ea3e93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps:\n",
    "1. register flow\n",
    "2. grab param files with glob\n",
    "3. for each param file, run flow. \n",
    "4. save all flow_run_ids\n",
    "5. after day? run state_checker\n",
    "6. rerun failed_flow runs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a752bd9-eff1-4e1c-b4c2-d745c47b0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. register flow\n",
    "2. submit all parameter as flow runs - keep ids \n",
    "3. in while loop:\n",
    "    ids = set()\n",
    "    \n",
    "    for id in list_of_submitted_ids:\n",
    "        if id not in ids & state!='succeeded':\n",
    "            rerun(id)\n",
    "        else:\n",
    "            ids.add(id)\n",
    "    if len(ids) == len(list_of_submitted_ids)\n",
    "\n",
    "top level while loop:\n",
    "    for loop of all possible flows\n",
    "        check state of each flow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dff78f-8272-4b53-a944-b365fce9dd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29ecb534-7072-4ce3-b96f-379b4424b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from upath import UPath\n",
    "import json\n",
    "import pathlib\n",
    "from prefect.client import Client\n",
    "from prefect.backend.flow import FlowView\n",
    "from prefect.backend.flow_run import FlowRunView, watch_flow_run\n",
    "from prefect.backend import FlowRunView\n",
    "from cmip6_downscaling.methods.common.containers import RunParameters\n",
    "from cmip6_downscaling.utils import str_to_hash\n",
    "from cmip6_downscaling import __version__ as version, config\n",
    "from cmip6_downscaling.methods.bcsd.flow import flow as bcsd_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eefa002-f5f3-4d07-9533-e6ca42e56889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "298d1cc7-da6a-4613-89c3-9de51d3b1787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-03 23:35:22+0000] INFO - prefect.Azure | Uploading bcsd/2022-05-03t22-56-50-029330-00-00 to prefect\n"
     ]
    },
    {
     "ename": "ResourceExistsError",
     "evalue": "The specified blob already exists.\nRequestId:78f43282-401e-0077-2746-5fe315000000\nTime:2022-05-03T23:35:22.9841418Z\nErrorCode:BlobAlreadyExists\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobAlreadyExists</Code><Message>The specified blob already exists.\nRequestId:78f43282-401e-0077-2746-5fe315000000\nTime:2022-05-03T23:35:22.9841418Z</Message></Error>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExistsError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 2\u001b[0m flow_id \u001b[38;5;241m=\u001b[39m \u001b[43mbcsd_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcmip6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mversion_group_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/prefect/core/flow.py:1727\u001b[0m, in \u001b[0;36mFlow.register\u001b[0;34m(self, project_name, build, labels, set_schedule_active, version_group_id, no_url, idempotency_key, **kwargs)\u001b[0m\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mresult\n\u001b[1;32m   1725\u001b[0m client \u001b[38;5;241m=\u001b[39m prefect\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m-> 1727\u001b[0m registered_flow \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_schedule_active\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_schedule_active\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion_group_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion_group_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43midempotency_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midempotency_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m registered_flow\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/prefect/client/client.py:1133\u001b[0m, in \u001b[0;36mClient.register\u001b[0;34m(self, flow, project_name, build, set_schedule_active, version_group_id, compressed, no_url, idempotency_key)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m project:\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not found. Run `prefect create project \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` to create it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1129\u001b[0m             project_name, project_name\n\u001b[1;32m   1130\u001b[0m         )\n\u001b[1;32m   1131\u001b[0m     )\n\u001b[0;32m-> 1133\u001b[0m serialized_flow \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: Any\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Configure environment.metadata (if using environment-based flows)\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flow\u001b[38;5;241m.\u001b[39menvironment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;66;03m# Set Docker storage image in environment metadata if provided\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/prefect/core/flow.py:1497\u001b[0m, in \u001b[0;36mFlow.serialize\u001b[0;34m(self, build)\u001b[0m\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1491\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1492\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA flow with the same name is already contained in storage; if you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1493\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchanged your Flow since the last build, you might experience \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1494\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected issues and should re-create your storage object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1495\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1496\u001b[0m         )\n\u001b[0;32m-> 1497\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: Optional[Storage]\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/prefect/storage/azure.py:155\u001b[0m, in \u001b[0;36mAzure.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_azure_block_blob_service\u001b[38;5;241m.\u001b[39mget_blob_client(\n\u001b[1;32m    148\u001b[0m         container\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer, blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows[flow_name]\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows[flow_name], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer)\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/azure/core/tracing/decorator.py:73\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/azure/storage/blob/_blob_client.py:716\u001b[0m, in \u001b[0;36mBlobClient.upload_blob\u001b[0;34m(self, data, blob_type, length, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload_blob_options(\n\u001b[1;32m    710\u001b[0m     data,\n\u001b[1;32m    711\u001b[0m     blob_type\u001b[38;5;241m=\u001b[39mblob_type,\n\u001b[1;32m    712\u001b[0m     length\u001b[38;5;241m=\u001b[39mlength,\n\u001b[1;32m    713\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blob_type \u001b[38;5;241m==\u001b[39m BlobType\u001b[38;5;241m.\u001b[39mBlockBlob:\n\u001b[0;32m--> 716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupload_block_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blob_type \u001b[38;5;241m==\u001b[39m BlobType\u001b[38;5;241m.\u001b[39mPageBlob:\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m upload_page_blob(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/azure/storage/blob/_upload_helpers.py:168\u001b[0m, in \u001b[0;36mupload_block_blob\u001b[0;34m(client, data, stream, length, overwrite, headers, validate_content, max_concurrency, blob_settings, encryption_options, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m         \u001b[43mprocess_storage_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ResourceModifiedError \u001b[38;5;28;01mas\u001b[39;00m mod_error:\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/azure/storage/blob/_shared/response_handlers.py:181\u001b[0m, in \u001b[0;36mprocess_storage_error\u001b[0;34m(storage_error)\u001b[0m\n\u001b[1;32m    178\u001b[0m error\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (error\u001b[38;5;241m.\u001b[39mmessage,)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise error from None\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/azure/storage/blob/_upload_helpers.py:99\u001b[0m, in \u001b[0;36mupload_block_blob\u001b[0;34m(client, data, stream, length, overwrite, headers, validate_content, max_concurrency, blob_settings, encryption_options, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         encryption_data, data \u001b[38;5;241m=\u001b[39m encrypt_blob(data, encryption_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     98\u001b[0m         headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-ms-meta-encryptiondata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m encryption_data\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjusted_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblob_http_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblob_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_response_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_stream_total\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjusted_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupload_stream_current\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtier\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblob_tags_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblob_tags_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimmutability_policy_expiry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimmutability_policy_expiry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimmutability_policy_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimmutability_policy_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegal_hold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegal_hold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m use_original_upload_path \u001b[38;5;241m=\u001b[39m blob_settings\u001b[38;5;241m.\u001b[39muse_byte_buffer \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    116\u001b[0m     validate_content \u001b[38;5;129;01mor\u001b[39;00m encryption_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    117\u001b[0m     blob_settings\u001b[38;5;241m.\u001b[39mmax_block_size \u001b[38;5;241m<\u001b[39m blob_settings\u001b[38;5;241m.\u001b[39mmin_large_block_upload_threshold \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(stream, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mseekable() \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(stream, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(stream, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtell\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_original_upload_path:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/azure/storage/blob/_generated/operations/_block_blob_operations.py:245\u001b[0m, in \u001b[0;36mBlockBlobOperations.upload\u001b[0;34m(self, content_length, body, timeout, transactional_content_md5, metadata, tier, request_id_parameter, blob_tags_string, immutability_policy_expiry, immutability_policy_mode, legal_hold, blob_http_headers, lease_access_conditions, cpk_info, cpk_scope_info, modified_access_conditions, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m201\u001b[39m]:\n\u001b[0;32m--> 245\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mStorageError, response)\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/azure/core/exceptions.py:105\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    104\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mResourceExistsError\u001b[0m: The specified blob already exists.\nRequestId:78f43282-401e-0077-2746-5fe315000000\nTime:2022-05-03T23:35:22.9841418Z\nErrorCode:BlobAlreadyExists\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobAlreadyExists</Code><Message>The specified blob already exists.\nRequestId:78f43282-401e-0077-2746-5fe315000000\nTime:2022-05-03T23:35:22.9841418Z</Message></Error>"
     ]
    }
   ],
   "source": [
    "retries = 3\n",
    "flow_id = bcsd_flow.register(project_name='cmip6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47aa9da-f418-43a2-815c-e2dcdbd5d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = json.loads(pathlib.Path('test.json').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c6dbe53-56a1-44b1-81ce-3eb3a17d0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae19c221-7385-4a6d-bd90-d861beade550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flow(flow_id: str, param_file_path: str) -> list[str]:\n",
    "\n",
    "    json_path = pathlib.Path(param_file_path).read_text()\n",
    "    flow_hash = str_to_hash(json_path)\n",
    "    param_dict = json.loads(json_path)\n",
    "\n",
    "    flow_run_id = client.create_flow_run(flow_id=flow_id, parameters=param_dict)\n",
    "    flow_run = FlowRunView.from_flow_run_id(flow_run_id)\n",
    "    run_url = client.get_cloud_url(\"flow-run\", flow_run_id)\n",
    "    return flow_run_id, flow_run, run_url, flow_hash, param_file_path\n",
    "\n",
    "\n",
    "def check_flow_status(flow_run):\n",
    "    elapsed_time = 0\n",
    "    while not flow_run.state.is_finished() and elapsed_time < 3:\n",
    "        time.sleep(1)\n",
    "        elapsed_time += 1\n",
    "        flow_run = flow_run.get_latest()\n",
    "    return flow_run\n",
    "\n",
    "\n",
    "def rerun_flow(flow_run, flow_run_id, param_file):\n",
    "\n",
    "    flow_run = check_flow_status(flow_run)\n",
    "\n",
    "    if flow_run.state.is_successful():\n",
    "        return ''\n",
    "    else:\n",
    "        # we can add more retries here -- more complex for now\n",
    "        flow_run_id, flow_run, run_url, flow_hash, param_file_path = run_flow(\n",
    "            flow_run_id, param_file\n",
    "        )\n",
    "        flow_run = check_flow_status(flow_run)\n",
    "\n",
    "        if flow_run.state.is_failed():\n",
    "            return param_file_path\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ced9bc42-5119-4cc8-b032-c698eaa88783",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "list_of_params = retrieve_test_parms()[0:2]\n",
    "for param_file_path in list_of_params:\n",
    "    runs.append(run_flow(flow_id, param_file_path))\n",
    "\n",
    "failed_param_file_list = []\n",
    "for flow_run_id, flow_run, run_url, flow_hash, param_file_path in runs:\n",
    "    rerun_flow_status = rerun_flow(flow_run, flow_run_id, param_file)\n",
    "    if len(rerun_flow_status) != 0:\n",
    "        failed_param_file_list.append(rerun_flow_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8e7f2-eaa5-4a02-b4e4-6cc21c3d7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = UPath(config.get(\"storage.results.uri\")) / version\n",
    "\n",
    "downscaling_methods = ['bcsd']\n",
    "method = 'bcsd'\n",
    "_prefect_register_str = (\n",
    "    \"\"\"prefect register --project \"cmip6\" -p ../methods/{downscaling_method}/flow.py\"\"\"\n",
    ")\n",
    "_prefect_run_str = \"\"\"prefect run -i \"{flow_run_id}\" --param-file {param_file}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf0f5d7e-c483-4f42-8461-764a103a6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_run_params_from_json(parameter_fpath: str) -> RunParameters:\n",
    "\n",
    "    # run_parameters.run_id_hash\n",
    "    # target2 = results_dir / 'runs' / run_parameters.run_id / 'latest.json'\n",
    "\n",
    "    df = pd.read_json(parameter_fpath)\n",
    "    run_parameters = RunParameters(\n",
    "        method=df.method.iloc[0],\n",
    "        obs=df.obs.iloc[0],\n",
    "        model=df.model.iloc[0],\n",
    "        member=df.member.iloc[0],\n",
    "        grid_label=df.grid_label.iloc[0],\n",
    "        table_id=df.table_id.iloc[0],\n",
    "        scenario=df.scenario.iloc[0],\n",
    "        variable=df.variable.iloc[0],\n",
    "        latmin=df.latmin.iloc[0],\n",
    "        latmax=df.latmax.iloc[0],\n",
    "        lonmin=df.lonmin.iloc[0],\n",
    "        lonmax=df.lonmax.iloc[0],\n",
    "        train_dates=[df.train_period.iloc[0], df.train_period.iloc[1]],\n",
    "        predict_dates=[df.predict_period.iloc[0], df.predict_period.iloc[1]],\n",
    "    )\n",
    "\n",
    "    return run_parameters\n",
    "\n",
    "\n",
    "def retrieve_test_parms():\n",
    "    \"\"\"retrieve list of all .json param files in method subdir\"\"\"\n",
    "    return glob.glob('../../configs/flow_runner_test/*.json')\n",
    "\n",
    "\n",
    "def register_flow(method: str) -> str:\n",
    "    \"\"\"Register flow with prefect cloud and return flow_run_id for running flows\"\"\"\n",
    "\n",
    "    print('registering flow on prefect cloud')\n",
    "    flow_id = bcsd_flow.register(project_name='cmip6')\n",
    "    return flow_id\n",
    "\n",
    "\n",
    "def check_run_failed(run_id: str) -> bool:\n",
    "    flow_run = FlowRunView.from_flow_run_id(run_id)\n",
    "    flow_status_is_failed = FlowRunView.from_flow_run_id(run_id).state.is_failed()\n",
    "\n",
    "    return flow_status_is_failed\n",
    "\n",
    "\n",
    "def check_run_status(run_id: str) -> bool:\n",
    "    flow_run = FlowRunView.from_flow_run_id(run_id)\n",
    "    flow_state_finished_status = flow_run.state.is_finished()\n",
    "\n",
    "    return flow_state_finished_status\n",
    "\n",
    "\n",
    "# failed_runs = []\n",
    "# while flow_state_finished_status == False:\n",
    "#         flow_run = FlowRunView.from_flow_run_id(run_id)\n",
    "#         flow_state_finished_status = flow_run.state.is_finished()\n",
    "#         time.sleep(60)\n",
    "#     flow_status_is_failed = FlowRunView.from_flow_run_id(run_id).state.is_failed()\n",
    "#     if flow_status_is_failed: #if True, run has failed\n",
    "#         failed_runs.append(run_id)\n",
    "\n",
    "\n",
    "# def run_flow(param_file: str, flow_id: str) -> list:\n",
    "\n",
    "#         print(param_file)\n",
    "#         sys_output = os.popen(\n",
    "#             _prefect_run_str.format(flow_run_id=flow_id, param_file=param_file)\n",
    "#         ).read()\n",
    "#         run_id = sys_output.split('UUID: ')[1].split('\\n')[0]\n",
    "#         run_url = sys_output.split('URL: ')[1].split('\\n')[0]\n",
    "#         print(run_url)\n",
    "\n",
    "#         return [run_id, run_url]\n",
    "\n",
    "\n",
    "def check_run_status(run_id_list: list) -> list:\n",
    "    failed_runs = []\n",
    "    for run_id in run_id_list:\n",
    "        flow_state_finished_status = check_run_status(run_id)\n",
    "        flow_status_is_failed = check_run_failed(run_id)\n",
    "\n",
    "        if flow_status_is_failed:\n",
    "            failed_runs.append(run_id)\n",
    "    return failed_runs\n",
    "\n",
    "\n",
    "def run_all_param_files(param_file_list: list) -> list:\n",
    "    run_id_list = []\n",
    "    flow_id = register_flow(method)\n",
    "    for param_file in param_file_list:\n",
    "        flow_return = run_flow(param_file, flow_id)\n",
    "        run_id_list.append(flow_return[0])\n",
    "    print(run_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a725b7f-4cb4-41fc-94ba-c567bc4bf49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registering flow on prefect cloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/carbonplan_data/__init__.py:29: UserWarning: CARBONPLAN_DATA environment variable not set, `carbonplan.data.cat` may not work as expected.Known data locations include: ['https://storage.googleapis.com/carbonplan-data', 'https://carbonplan.blob.core.windows.net/carbonplan-data'].\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_asdf', 'id_asdf', 'id_asdf', 'id_asdf', 'id_asdf', 'id_asdf', 'id_asdf']\n"
     ]
    }
   ],
   "source": [
    "# first pass\n",
    "param_file_list = retrieve_test_parms()\n",
    "run_id_list = run_all_param_files(param_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e1b8970-ab56-44b1-8396-0ce5eea992b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a947bdf-ee6b-4916-a76f-d881925bd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second pass\n",
    "failed_runs = check_run_status(run_id_list)\n",
    "second_failed_runs = run_all_param_files(failed_runs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
